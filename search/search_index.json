{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to MkDocs \u00b6 For full documentation visit mkdocs.org . Commands \u00b6 mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs help - Print this help message. Project layout \u00b6 mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Home"},{"location":"#welcome-to-mkdocs","text":"For full documentation visit mkdocs.org .","title":"Welcome to MkDocs"},{"location":"#commands","text":"mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs help - Print this help message.","title":"Commands"},{"location":"#project-layout","text":"mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Project layout"},{"location":"Mengukur Jarak Data (Penambangan Data)/","text":"Mengukur Jarak Data Mengukur Jarak Tipe Numerik \u200b Ada beberapa ukuran similaritas data ukuran jarak, diantaranya: a) Minkowski Distance \u200b Kelompok Minkowski diantaranya adalah Euclidean distance dan Manhattan distance, Minkowski distance dinyatakan dengan: $$ d _ { \\operatorname { min } } = ( \\ sum _ { i = 1 } ^ { n } | x _ { i } - y _ { i } | ^ { m } ) ^ { \\frac { 1 } { m } } , m \\geq 1 $$ b) Manhattan Distance \u200b Manhattan distance ialah kasus khusus dimana jarak dari minkoswski distance pada m= 1. Manhattan distance sensitif terhadap outlier. Jika ukuran ini digunakan dalam algoritma cleustering maka bentuk cleuster adalah hyper-rectangular. Ukuran ini dinyatakan dengan: $$ d _ { \\operatorname { man } } = \\sum _ { i = 1 } ^ { n } \\left| x _ { i } - y _ { i } \\right| $$ c) Euclidean Distance \u200b Euclidean distance ialah metode pengukuran yang paling sering digunakan, euclidean distance menghitung akar dari kuadrat perbedaan dua buah atau lebih vektor. Metode ini dapat digunakan untuk mendeteksi tingkat ketidaksamaan citra dengan cara mengisi nilai vektor p dan q dengan nilai fitur citra yang akan dideteksi tingkat ketidaksamaannya. Euclidean distance memiliki kelemahan yaitu jika dua vektor data tidak memiliki nilai atribut yang sama, kemungkinan memiliki jarak yang lebih kecil daripada pasangan vektro data lainnya yang mengandung nilai atribut yang sama. d) Average Distance \u200b Dikarenakan kekurangan dari jarak euclidian distance diatas, maka rata-rata jarak adalah versi modifikasi dari jarak euclidian distance untuk memperbaiki hasil. Rata-rata jarak didefinisikan dengan: $$ d _ { a v e } = \\left ( \\frac { 1 } { n } \\sum _ { i = 1 } ^ { n } ( x _ { i } - y _ { i } ) ^ { 2 } \\right) ^ { \\frac { 1 } { 2 } } $$ e) Weighted Euclidean Distance \u200b Jika berdasarkan tingkat penting dari masing-masing atribut ditentukan, maka weihted euclidean distance adalah modifikasi lain dari jarak euclidean distance yang dapat digunakan. Ukuran ini didefinisikan dengan: d _ { w e } = \\left ( \\sum _ { i = 1 } ^ { n } w _ { i } ( x _ { i } - y _ { i } \\right) ^ { 2 } ) ^ { \\frac { 1 } { 2 } } d _ { w e } = \\left ( \\sum _ { i = 1 } ^ { n } w _ { i } ( x _ { i } - y _ { i } \\right) ^ { 2 } ) ^ { \\frac { 1 } { 2 } } \u200b f) Chord Distance \u200b Chord distance adalah salah satu ukuran modifikasi euclidean distance untuk mengatasi kekurangan dari euclidean distance. Jarak ini dapat juga dihitung dari data yang tidak dinormalisasi, Chord distance didefinisikan dengan: $$ d _ { w e } = \\left ( \\sum _ { i = 1 } ^ { n } w _ { i } ( x _ { i } - y _ { i } \\right) ^ { 2 } ) ^ { \\frac { 1 } { 2 } } $$ \u200b \u200b g) Mahalanobis Distance \u200b Jarak mahalanobis yang teratur dapat digunakan untuk mengekstaksi hyperellipsoidal clusters. Jarak mahanalobis dapat mengurangi distorsi yang disebabkan oleh korelasi linier antar fitur dengan menerapkan transformasi pemutihan ke data atau dengan menggunakan kuadrat jarak mahalanobis. Mahalanobis distance didefinisikan dengan: $$ d _ { m a h } = \\sqrt { ( x - y ) S ^ { - 1 } ( x - y ) ^ { T } } $$ h) Cosine Measure \u200b Ukuran cosine similarty lebih banyak digunakan dalam similaritas dokumen dan didefinisikan dengan: $$ Cosine(x,y)=\\frac { \\sum _ { i = 1 } ^ { n } x _ { i } y _ { i } } { | x | _ { 2 } | y | _ { 2 } } $$ i) Pearson Correlation \u200b Pearson correlation banyak digunakan pada data expresi gen. ukuran ini menghitung antara dua bentuk pola expresi gen. pearson corralatin didefinisikan dengan: $$ Pearson ( x , y ) = \\frac { \\sum _ { i = 1 } ^ { n } ( x _ { i } - \\mu _ { x } ) ( y _ { i } - \\mu _ { y } ) } { \\sqrt { \\sum _ { i = 1 } ^ { n } ( x _ { i } - y _ { i } ) ^ { 2 } } \\sqrt { \\sum _ { i = 1 } ^ { n } ( x _ { i } - y _ { i } ) ^ { 2 } } } $$ Mengukur Jarak Atribut Binary \u200b Similaritas dan desimilirity untuk objek yang dijelaskan oleh atribut biner simetris atau asimetris. Aatribut biner hanya memiliki dua status: 0 dan 1 Contoh atribut perokok menggambarkan seorang pasien, misalnya, 1 menunjukkan bahwa pasien merokok, sedangkan 0 menunjukkan pasien tidak merokok. Memperlakukan atribut biner sebagai atribut numerik tidak diperkenankan. Oleh karena itu, metode khusus untuk data biner diperlukan untuk membedakan komputasi. Dissimilarity dan Similarity Rumus dissimilarity antara ii dan jj dan dinyatankan sebagai atribut biner simetris adalah: $$ \\begin{align} d(i,j) = \\frac {r+s}{q+r+s+t} \\end{align} $$ Rumus dissimilarity antara ii dan jj dan dinyatankan sebagai atribut biner asimetris adalah: $$ \\begin{align} d(i,j) = \\frac {r+s}{q+r+s} \\end{align} $$ Persamaan similarity Jaccard coefficient rumusnya adalah: $$ \\begin{align} sim(i,j) = \\frac {q}{q+r+s} = 1-d(i,j) \\end{align} $$ Mengukur Jarak Menggunakan Catergorical Overlay Metric Untuk semua atribut bertipe nominal, ukuran jarak yang paling sederhana adalah Overlay Metric (OM) dinyatakan dengan $$ \\begin{align} d(x,y) = \\sum_{i=1}^n\\delta(a_i(x),a_i(y)) \\end{align} $$ Dimana nn adalah banyaknya atribut, ai(x)ai(x) dan ai(y)ai(y) adalah nilai atribut ke ii yaitu AiAi dari masing-masing objek xx dan yy, \u03b4(ai(x))(ai(y))\u03b4(ai(x))(ai(y)) adalah 0 jika ai(x)ai(x) = ai(y)ai(y) dan 1 jika sebaliknya. Value Difference Metri VDM dikenalkan oleh Standfill and Waltz, versi sederhana dari VDM tanpa skema pembobotan didefinsisikan dengan: $$ \\begin{align} d(x,y) = \\sum_{i=1}^n\\sum_{c=1}^C|P(c|a_i(x)) - P(c|a_i(y)) \\end{align} $$ Dimana CC adalah banyaknya kelas, P(c|ai(x))P(c|ai(x)) adalah probabilitas bersyarat dimana kelas xx adalah cc dari atribut AiAi, yang memilki nilai ai(x)ai(x), P(c|ai(y))P(c|ai(y)) adalah probabilitas bersyarat dimana kelas y adalah c dengan atribut AiAi memiliki nilai ai(y). Minimum Risk Metric Ukuran ini dipresentasikan oleh Blanzieri and Ricci, berbeda dari SFM yaitu meminimumkan selisih antara kesalahan berhingga dan kesalahan asymtotic. MRM meminimumkan risk of misclassification yang didefinisikan dengan: $$ \\begin{align} d(x,y) = \\sum_{c=1}^C|P(c|x) (1 - P(c|y)) \\end{align} $$ Mengukur Jarak Tipe Ordinal Perlakuan untuk atribut ordinal adalah cukup sama dengan atribut numerik ketika menghitung disimilarity antara objek. Misalkan ff adalah atribut-atribut dari atribut ordinak dan nn objek. Menghitung disimilarity terhadap ff fitur sebagai berikut: - Nilai ff untuk objek ke-ii adalah xifxif, dan ff memiliki MfMf status urutan, mewakili peringkat 1,...,Mf1,...,Mf ganti setiap XifXif dengan peringkatnya rif\u22081...MMfrif\u22081...MMf Karena setiap atribut ordinal dapat memiliki jumlah state yang berbeda, diperlukan untuk memetakan rentang setiap atribut ke [0,0, 1.0] sehingga setiap atribut memiliki bobot yang sama. Perl melakukan normalisasi data dengan mengganti peringkat rifrif dengan $$ \\begin{align} z_{if} = \\frac{r_{if} - 1}{M_f - 1} \\end{align} $$ Dissimilarity kemudian dihitung dengan menggunakan ukuran jarak seperti atribut numerik dengan data yang baru setelah ditransformasi zif Mengukur Jarak Tipe Campuran $$ \\begin{align} d(i,j) = \\frac{\\sum_{f=1}^p\\delta_{ij}^{(f)} d_{ij}^{(f)}}{\\sum_{f=1}^pd_{ij}^{(f)}} \\end{align} $$","title":"Menghitung Jarak Data"},{"location":"Pengertian (Andi)/","text":"Mean(Rata-rata) \u200b Pengertian mean adalah nilai rata-rata dari beberapa buah data. Nilai mean dapat ditentukan dengan cara membagi jumlah data dengan banyaknya data. \u200b Rumus untuk mencari mean seperti berikut: $$ \\overline{x}=\\frac{\\sum_{i=1}^{N} x_{i}}{N}=\\frac{x_{1}+x_{2}+\\cdots+x_{N}}{N} $$ Median \u200b pengertian median adalah suatu cara untuk menentukan letak tengah sebuah data setelah data disusun menurut urutan nilainya. \u200b Rumus untuk mencari median seperti berikut: $$ M e=x_{i j}+\\left(\\frac{\\frac{n}{2}-f_{k i j}}{f_{i}}\\right) p $$ Modus \u200b Pengertian modus adalah nilai yang sering muncul. Untuk ingin melihat suatu hasil akhir dari modus maka harus menentukan kelas pada tabel dengan memilih frekuensi yang paling banyak. \u200b Rumus untuk mencari modus seperti berikut: $$ \\text { mean }-\\text { mode } \\approx 3 \\times(\\text { mean }-\\text { median }) $$ Standard deviasi \u200b Pengertian standard deviasi adalah nilai statistik yang digunakan untuk menentukan bagaimana sebaran data dalam sampel, dan seberapa dekat titik data individu ke mean atau rata-rata nilai sampel. \u200b Rumus untuk mencari standard deviasi sebagai berikut: $$ \\sigma ^ { 2 } = \\frac { 1 } { N } \\sum _ { i = 1 } ^ { N } ( x _ { i } - \\overline { x } ) ^ { 2 } = ( \\frac { 1 } { N } \\sum _ { i = 1 } ^ { N } x _ { i } ^ { 2 } ) - \\overline { x } ^ { 2 } $$ \u200b Varian \u200b Pengertian varian adalah ukuran seberapa jauh sebuah kumpulan bilangan tersebar, varian juga merupakan salah satu pendeskripsi dari sebuah distribusi probabilitas. \u200b Rumus untuk mencari devian sebagai berikut: $$ \\sigma = \\frac { 1 } { N } \\sum _ { i = 1 } ^ { N } ( x _ { i } - \\overline { x } ) ^ { 2 } = ( \\frac { 1 } { N } \\sum _ { i = 1 } ^ { N } x _ { i } ^ { 2 } ) - \\overline { x } ^ { 2 } $$ Skewness (Kemiringan) \u200b Pngertian skewness adalah derajat ketidaksimetrisan atau distribusi. \u200b Rumus untuk mencari skewness sebagai berikut: $$ s k=\\frac{\\overline{X}-M o}{s} $$ 7.Kuartil \u200b Pengertian kuartil adalah nilai-nilai yang membagi data yang telah diurutkan kedalam empat bagian yang nilainya sama besar, Kuartil terbagi menjadi 3 macam antara lain: a) Kuartil bawah (k1) b) kuartil tengah (k2) c)) Kuartil atas (k3) \u200b Rumus untuk memcri kuartil 1,2, dan 3 sebagai berikut: IQR=Q3\u2212Q1 IQR=Q3\u2212Q1 import pandas as pd from scipy import stats import numpy as np import seaborn as sns import matplotlib as plt data = pd.read_csv(\"ANDIAJADOANG.csv\",delimiter=\";\") cm = sns.light_palette(\"gold\", as_cmap=True) data.style.background_gradient(cmap=cm) colum = data.columns.tolist() for x in colum : ds = [x for x in data[x]] desc = data[x].describe() array = [x for x in desc] print(\"Detail kolom\",x) print(\"rata-rata: \",array[1]) print(\"Median: \",np.median(np.array(ds))) print(\"Modus: \",stats.mode(ds)) print(\"Standard deviasi: \",np.std(ds)) print(\"varian: \",stats.variation(ds)) print(\"Skewness: \",stats.skew(ds)) print(\"Quartil 1: \",array[4]) print(\"Quartil 2: \",array[5]) print(\"Quartil 3: \",array[6]) sns.distplot(data[x]) \u200b","title":"Statistika"}]}